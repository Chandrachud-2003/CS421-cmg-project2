{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension 1 - Autocomplete and Suggesting Method Names\n",
    "\n",
    "In this extension I appleid the current Python2Vec model in other software engineering applications,like autocomplete and suggesting method names.\n",
    "\n",
    "autocomplete function:\n",
    "\n",
    "- Tokenize the prefix string into a list of words.\n",
    "- Get the top 5 most similar words to each word in the prefix list using the most_similar method of the trained Word2Vec model.\n",
    "- Merge the lists of similar words for each prefix word and remove duplicates.\n",
    "- Remove any words that are already in the prefix list to avoid duplicates.\n",
    "- Return the top 5 similar words that are not already in the prefix list.\n",
    "\n",
    "suggest_method_names function:\n",
    "\n",
    "- Tokenize the input code context into a list of words using NLTK's word_tokenize function.\n",
    "- Iterate through the list of words and identify any words that could be method names, based on the following criteria:\n",
    "- The word starts with a lowercase letter.\n",
    "- The word appears after a period (indicating a method call) or a newline (indicating a function definition).\n",
    "- The word is not a reserved Python keyword or built-in function name.\n",
    "- For each identified method name, get the top 5 most similar words using the most_similar method of the trained Word2Vec model, excluding any words that are already in the context or are reserved keywords/built-in function names.\n",
    "- Return the top 5 similar words for each identified method name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Repositories/matplotlib already exists\n",
      "Python Repositories/scikit-learn already exists\n",
      "Python Repositories/numpy already exists\n",
      "Python Repositories/django already exists\n",
      "Python Repositories/scipy already exists\n",
      "Python Repositories/ansible already exists\n",
      "Python Repositories/scrapy already exists\n",
      "Python Repositories/Mailpile already exists\n",
      "Python Repositories/sshuttle already exists\n",
      "Python Repositories/pandas already exists\n",
      "Python Repositories/flask already exists\n",
      "Python Repositories/requests already exists\n",
      "Python Repositories/sentry already exists\n",
      "Python Repositories/salt already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Python Repositories/NewsBlur'...\n",
      "Updating files:  97% (5973/6157)\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Repositories/beets already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating files: 100% (6157/6157), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create the 'Python Repositories' directory if it doesn't already exist\n",
    "if not os.path.exists('Python Repositories'):\n",
    "    os.makedirs('Python Repositories')\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# List of regular link repositories to download\n",
    "repos = ['matplotlib', 'scikit-learn', 'numpy', 'django', 'scipy', 'ansible', 'scrapy', 'Mailpile', 'sshuttle']\n",
    "\n",
    "# Clone each repository into the 'Python Repositories' directory\n",
    "for repo in repos:\n",
    "    # Checking if the repository already exists\n",
    "    if not os.path.exists(f'Python Repositories/{repo}'):\n",
    "        subprocess.run(['git', 'clone', f'https://github.com/{repo}/{repo}.git', f'Python Repositories/{repo}'])\n",
    "    else:\n",
    "        print(f'Python Repositories/{repo} already exists')\n",
    "\n",
    "# List of non regular link repositories to download\n",
    "additional_repos = ['https://github.com/pandas-dev/pandas', 'https://github.com/pallets/flask', 'https://github.com/psf/requests', 'https://github.com/getsentry/sentry', 'https://github.com/saltstack/salt', 'https://github.com/samuelclay/NewsBlur', 'https://github.com/beetbox/beets']\n",
    "\n",
    "# Clone each repository into the 'Python Repositories' directory\n",
    "for repo in additional_repos:\n",
    "    # Checking if the repository already exists\n",
    "    if not os.path.exists(f'Python Repositories/{repo.split(\"/\")[-1]}'):\n",
    "        subprocess.run(['git', 'clone', repo, f'Python Repositories/{repo.split(\"/\")[-1]}'])\n",
    "    else:\n",
    "        print(f'Python Repositories/{repo.split(\"/\")[-1]} already exists')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import gensim\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Load the trained Python2Vec model\n",
    "model = gensim.models.Word2Vec.load('python2vec.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the trained Python2Vec model for autocomplete and suggesting method names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate autocomplete suggestions using the Word2Vec model\n",
    "def autocomplete(method_name):\n",
    "    # Get the most similar method names\n",
    "    similar_methods = model.wv.most_similar(positive=[method_name], topn=10)\n",
    "\n",
    "    # Return the most similar method names\n",
    "    return similar_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to suggest method names\n",
    "def suggest_method_names(context):\n",
    "    \"\"\"\n",
    "    Given a code context, generate a list of suggested method names based on the trained Python2Vec model.\n",
    "    \"\"\"\n",
    "    # Tokenize the context\n",
    "    context_tokens = [token.lower() for token in word_tokenize(context) if token.isalpha()]\n",
    "\n",
    "    # Get the vector representation of the context by averaging the vectors of its constituent tokens\n",
    "    context_vector = np.mean([model.wv[token] for token in context_tokens if token in model.wv], axis=0)\n",
    "\n",
    "    # Find the 10 most similar words to the context vector\n",
    "    similar_words = model.wv.similar_by_vector(context_vector, topn=10)\n",
    "\n",
    "    # Return the words with the highest similarity that aren't already in the context\n",
    "    return [word for word, similarity in similar_words if word not in context_tokens][:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage of the autocomplete and suggest_method_names functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocomplete suggestions for np: \n",
      "\n",
      "[('full_like', 0.6535319685935974), ('amax', 0.6041274070739746), ('set_numeric_ops', 0.6008948087692261), ('ones_like', 0.5989103317260742), ('unit_impulse', 0.597734272480011), ('asanyarray', 0.5955049395561218), ('hstack', 0.5954834818840027), ('nverts', 0.5910012125968933), ('vstack', 0.5907800197601318), ('logical_not', 0.58856600522995)]\n",
      "\n",
      "Suggested method names for import pandas as pd\n",
      "\n",
      "def process_data(data):\n",
      " df = pd.DataFrame(data)\n",
      " # TODO: add more code here\n",
      ": \n",
      "\n",
      "['testdata', 'notnull', 'from_dict', 'merge_ordered', 'dtl']\n"
     ]
    }
   ],
   "source": [
    "prefix = 'np'\n",
    "autocomplete_results = autocomplete(prefix)\n",
    "print(f'Autocomplete suggestions for {prefix}: \\n\\n{autocomplete_results}')\n",
    "\n",
    "context = 'import pandas as pd\\n\\ndef process_data(data):\\n df = pd.DataFrame(data)\\n # TODO: add more code here\\n'\n",
    "method_suggestions = suggest_method_names(context)\n",
    "print(f'\\nSuggested method names for {context}: \\n\\n{method_suggestions}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
